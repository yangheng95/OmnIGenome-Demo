importos
importnumpyasnp
importtorch
fromomnigenomeimport(
ClassificationMetric,
AutoBenchConfig,
OmniGenomeDatasetForTokenClassification,
OmniGenomeModelForTokenClassification,
)
classDataset(OmniGenomeDatasetForTokenClassification):
    defprepare_input(self,instance,**kwargs):
        sequence=(
instance.get("seq",None)
if"seq"ininstance
elseinstance.get("sequence",None)
)
mutation=instance.get("mut",None)
labels=[1ifmutation[i]!=sequence[i]else0foriinrange(len(mutation))]
tokenized_inputs=self.tokenizer(
mutation+sequence[len(mutation):],
padding="do_not_pad",
truncation=True,
max_length=self.max_length,
return_tensors="pt",
**kwargs,
)
forcolintokenized_inputs:
            tokenized_inputs[col]=tokenized_inputs[col].squeeze()
iflabelsisnotNone:
            labels=np.array(labels,dtype=np.int64)
labels=labels.reshape(-1)
padded_labels=np.concatenate([[-100],labels,[-100]])
tokenized_inputs["labels"]=torch.tensor(padded_labels,dtype=torch.int64)
returntokenized_inputs
config_dict={
"task_name":"RNA-SNMD",
"task_type":"token_classification",
"label2id":{"0":0,"1":1},
"num_labels":2,
"epochs":10,
"learning_rate":2e-5,
"weight_decay":1e-5,
"batch_size":32,
"max_length":220,
"patience":10,
"seeds":[45,46,47],
"compute_metrics":ClassificationMetric(
ignore_y=-100,average="macro"
).roc_auc_score,
"train_file":f"{os.path.dirname(__file__)}/train.json",
"test_file":f"{os.path.dirname(__file__)}/test.json",
"valid_file":f"{os.path.dirname(__file__)}/valid.json"
ifos.path.exists(f"{os.path.dirname(__file__)}/valid.json")
elseNone,
"dataset_cls":Dataset,
"model_cls":OmniGenomeModelForTokenClassification,
"loss_fn":torch.nn.CrossEntropyLoss(weight=torch.tensor([1.0,100.0])),
}
bench_config=AutoBenchConfig(config_dict)